{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9373677,"sourceType":"datasetVersion","datasetId":5685456}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Team DSTI - ISIC 2024\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# Import all necessary packages\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport h5py\nfrom PIL import Image\nimport io\nimport torchvision.models as models\n\n# Disable version checking for albumentations\nA.core.transforms_interface.is_module_available = lambda _: False\n\n# Load Test Data\n# Define paths\ntest_hdf5_path = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\ntest_metadata_path = '/kaggle/input/isic-2024-challenge/test-metadata.csv'\n\n# Load metadata\ndf_test = pd.read_csv(test_metadata_path)\n\n# Define the SqueezeNetWithVSURF model\nclass SqueezeNetWithVSURF(nn.Module):\n    def __init__(self, num_classes=1, vsurf_size=5, dropout_rate=0.5):\n        super(SqueezeNetWithVSURF, self).__init__()\n        \n        # Load pre-trained SqueezeNet\n        self.squeezenet = models.squeezenet1_1(pretrained=False)\n        \n        # Replace the last convolutional layer\n        self.squeezenet.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n        \n        # Additional layers for VSURF features\n        self.vsurf_fc = nn.Sequential(\n            nn.Linear(vsurf_size, 32),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n        \n        # Combine features\n        self.final_fc = nn.Linear(num_classes + 32, num_classes)\n\n    def forward(self, x, vsurf):\n        # SqueezeNet forward pass\n        x = self.squeezenet(x)\n        x = x.view(x.size(0), -1)\n        \n        # VSURF features forward pass\n        vsurf = self.vsurf_fc(vsurf)\n        \n        # Combine features\n        combined = torch.cat((x, vsurf), dim=1)\n        \n        # Final classification\n        out = self.final_fc(combined)\n        \n        return out\n\n# Define Dataset Class and Transformation\nclass ISICDataset(Dataset):\n    def __init__(self, hdf5_file, df, transform=None):\n        self.hdf5_file = h5py.File(hdf5_file, 'r')\n        self.df = df\n        self.transform = transform\n        self.vsurf_columns = ['clin_size_long_diam_mm', 'tbp_lv_H', 'tbp_lv_deltaLBnorm', 'tbp_lv_perimeterMM', 'tbp_lv_Hext']\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        isic_id = self.df.iloc[idx]['isic_id']\n        img_bytes = self.hdf5_file[isic_id][()]\n        img = Image.open(io.BytesIO(img_bytes))\n        img = np.array(img)\n\n        if self.transform:\n            augmented = self.transform(image=img)\n            img = augmented['image']\n\n        # Convert VSURF features to float, replacing any non-numeric values with 0\n        vsurf_features = self.df.iloc[idx][self.vsurf_columns].values\n        vsurf_features = np.array([float(val) if isinstance(val, (int, float)) else 0.0 for val in vsurf_features])\n        vsurf_features = torch.tensor(vsurf_features, dtype=torch.float32)\n\n        return img, vsurf_features\n\n    def __del__(self):\n        self.hdf5_file.close()\n\n# Load Pretrained Model\ndef load_model(model_path):\n    model = SqueezeNetWithVSURF(num_classes=1, vsurf_size=5, dropout_rate=0.5)\n    state_dict = torch.load(model_path, map_location='cpu')  # Load to CPU to avoid CUDA issues\n    model.load_state_dict(state_dict)\n    model.eval()\n    return model\n\n# Prediction function\ndef predict(model, test_loader, device):\n    model.eval()\n    preds = []\n    \n    with torch.no_grad():\n        for inputs, vsurf_features in test_loader:\n            inputs = inputs.to(device)\n            vsurf_features = vsurf_features.to(device)\n            outputs = model(inputs, vsurf_features)\n            preds.append(torch.sigmoid(outputs).cpu().numpy())\n    \n    return np.concatenate(preds).flatten()\n\n# Make Prediction\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\nif __name__ == \"__main__\":\n    try:\n        # Set up paths\n        test_hdf5_path = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n        test_metadata_path = '/kaggle/input/isic-2024-challenge/test-metadata.csv'\n        model_path = '/kaggle/input/isic-2024-squeezenet-bes/best_model.pth'  # Update this path\n\n        # Set device\n        device = torch.cuda.is_available() and 'cuda' or 'cpu'\n        print(f\"Using device: {device}\")\n\n        # Load test data\n        df_test = pd.read_csv(test_metadata_path)\n        print(f\"Loaded test data with {len(df_test)} samples\")\n\n        # Define transforms\n        def get_transforms(*, data):\n            if data == 'valid':\n                return A.Compose([\n                    A.Resize(224, 224),\n                    A.Normalize(\n                        mean=[0.485, 0.456, 0.406],\n                        std=[0.229, 0.224, 0.225],\n                    ),\n                    ToTensorV2(),\n                ])\n\n        # Create test dataset and dataloader\n        test_dataset = ISICDataset(test_hdf5_path, df_test, transform=get_transforms(data='valid'))\n        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n        print(\"Created test dataloader\")\n\n        # Load model\n        model = load_model(model_path)\n        model = model.to(device)\n        print(\"Loaded model\")\n\n        # Make predictions\n        predictions = predict(model, test_loader, device)\n        print(f\"Made predictions for {len(predictions)} samples\")\n\n        # Create output DataFrame with raw probabilities\n        output_df = pd.DataFrame({\n            'isic_id': df_test['isic_id'],\n            'target': predictions  # Use the raw prediction probabilities\n        })\n\n        # Save the predictions to a CSV file for submission\n        output_df.to_csv('submission.csv', index=False)\n        print(\"Submission file created!\")\n        \n        # Display the first few rows\n        print(\"First few rows of predictions:\")\n        print(output_df.head())\n\n        print(\"Execution completed successfully\")\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        raise","metadata":{"execution":{"iopub.status.busy":"2024-09-12T09:19:38.436678Z","iopub.execute_input":"2024-09-12T09:19:38.436961Z","iopub.status.idle":"2024-09-12T09:20:06.471575Z","shell.execute_reply.started":"2024-09-12T09:19:38.436928Z","shell.execute_reply":"2024-09-12T09:20:06.470416Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Using device: cuda\nLoaded test data with 3 samples\nCreated test dataloader\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/2581120580.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(model_path, map_location='cpu')  # Load to CPU to avoid CUDA issues\n","output_type":"stream"},{"name":"stdout","text":"Loaded model\nMade predictions for 3 samples\nSubmission file created!\nFirst few rows of predictions:\n        isic_id    target\n0  ISIC_0015657  0.000474\n1  ISIC_0015729  0.011559\n2  ISIC_0015740  0.000343\nExecution completed successfully\n","output_type":"stream"}]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNLQHT/Q0FduaEBWMPoWP/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0541d1e811a54e3c954e00d7b616bac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94f6477611074ef6a9f5ac4323e32e13",
              "IPY_MODEL_1c33e049014b45dc93b735a21aaa2a49",
              "IPY_MODEL_53f89ccc3d914780ab219946a5e201fe"
            ],
            "layout": "IPY_MODEL_1d8dda237ab648bfb16f7ff73dacaafa"
          }
        },
        "94f6477611074ef6a9f5ac4323e32e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f95495ada42745b6bec750cf97ad7ff6",
            "placeholder": "​",
            "style": "IPY_MODEL_99017cc8d7fd4275b1e4588346454e2d",
            "value": "Evaluating: 100%"
          }
        },
        "1c33e049014b45dc93b735a21aaa2a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a24687be6a47bbba718c5087abfe85",
            "max": 940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d41144987c0a45e0a1e7977ec873273e",
            "value": 940
          }
        },
        "53f89ccc3d914780ab219946a5e201fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08af248b706543849e211180d4a31a40",
            "placeholder": "​",
            "style": "IPY_MODEL_f7531edd3bb2456d85d674577c14877c",
            "value": " 940/940 [00:29&lt;00:00, 33.92it/s]"
          }
        },
        "1d8dda237ab648bfb16f7ff73dacaafa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f95495ada42745b6bec750cf97ad7ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99017cc8d7fd4275b1e4588346454e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84a24687be6a47bbba718c5087abfe85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d41144987c0a45e0a1e7977ec873273e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08af248b706543849e211180d4a31a40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7531edd3bb2456d85d674577c14877c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6a0d79bd6b84a4ca22381e05bf56bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89a8a6211f804ec78c5b5fbde0186103",
              "IPY_MODEL_125feb460af94b5faf993913d2aea489",
              "IPY_MODEL_f1fae12dae104079be11126b6ef0d629"
            ],
            "layout": "IPY_MODEL_458e67f01ae64a2a9804f9a98e56b094"
          }
        },
        "89a8a6211f804ec78c5b5fbde0186103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c638d43fdb7c438b8b2026b651be42f5",
            "placeholder": "​",
            "style": "IPY_MODEL_7e443757050e4c9190920ccf2b84eb66",
            "value": "Evaluating: 100%"
          }
        },
        "125feb460af94b5faf993913d2aea489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b90c93dc1e246f997fb383b8f9f1968",
            "max": 940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df24fc1d08e74c549f548b2b6518b6ad",
            "value": 940
          }
        },
        "f1fae12dae104079be11126b6ef0d629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af941bf8e0e944e8b58010c22afda7ee",
            "placeholder": "​",
            "style": "IPY_MODEL_02c17eed95274a44bde100e7a63455d9",
            "value": " 940/940 [00:33&lt;00:00, 20.84it/s]"
          }
        },
        "458e67f01ae64a2a9804f9a98e56b094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c638d43fdb7c438b8b2026b651be42f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e443757050e4c9190920ccf2b84eb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b90c93dc1e246f997fb383b8f9f1968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df24fc1d08e74c549f548b2b6518b6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af941bf8e0e944e8b58010c22afda7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c17eed95274a44bde100e7a63455d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brandt-DSTI/Computer_Vision_ISIC_2024/blob/main/Copy_of_SN_BES_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk 0: Mount Google Drive and Copy Files\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "drive_hdf5_path = '/content/drive/MyDrive/isic-2024-challenge/train-image.hdf5'\n",
        "drive_metadata_path = '/content/drive/MyDrive/isic-2024-challenge/train-metadata.csv'\n",
        "local_hdf5_path = '/content/train-image.hdf5'\n",
        "local_metadata_path = '/content/train-metadata.csv'\n",
        "\n",
        "# Copy files from Drive to local Colab session\n",
        "shutil.copy(drive_hdf5_path, local_hdf5_path)\n",
        "shutil.copy(drive_metadata_path, local_metadata_path)\n",
        "\n",
        "print(\"Files copied to local Colab session.\")\n",
        "print(f\"Train HDF5 file exists: {os.path.exists(local_hdf5_path)}\")\n",
        "print(f\"Train metadata file exists: {os.path.exists(local_metadata_path)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0bbHL6ZzcQK",
        "outputId": "449d0333-e752-4ccb-fd06-3ef25a2a899e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Files copied to local Colab session.\n",
            "Train HDF5 file exists: True\n",
            "Train metadata file exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk 1: Setup and Imports\n",
        "\n",
        "# Install required packages\n",
        "!pip install albumentations timm tqdm h5py opencv-python-headless imbalanced-learn mealpy\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import logging\n",
        "\n",
        "from PIL import Image\n",
        "import io\n",
        "import h5py\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "from mealpy import FloatVar, BES\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, classification_report, f1_score, roc_curve, auc\n",
        "\n",
        "import timm\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(filename='optimization.log', level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Random seed setup for reproducibility\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "\n",
        "# Load metadata\n",
        "df_train = pd.read_csv(local_metadata_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hpd4b-c0e97",
        "outputId": "e6c9d61c-37cb-4e75-f700-b413b5a3cab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.14)\n",
            "Collecting timm\n",
            "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.11.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Collecting mealpy\n",
            "  Downloading mealpy-3.0.1-py3-none-any.whl.metadata (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.23.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.12.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.8.2)\n",
            "Requirement already satisfied: albucore>=0.0.13 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.14)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.0+cu121)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.6)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (2.1.4)\n",
            "Collecting opfunu>=1.0.0 (from mealpy)\n",
            "  Downloading opfunu-1.0.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from opfunu>=1.0.0->mealpy) (2.32.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->mealpy) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->mealpy) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.20.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.8.28)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->mealpy) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mealpy-3.0.1-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.3/386.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opfunu-1.0.4-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opfunu, timm, mealpy\n",
            "Successfully installed mealpy-3.0.1 opfunu-1.0.4 timm-1.0.9\n",
            "Using device: cuda\n",
            "GPU: NVIDIA L4\n",
            "Number of GPUs: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e64251c63e1e>:67: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_train = pd.read_csv(local_metadata_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk 2: Define Dataset and Augmentation\n",
        "\n",
        "class ISICDataset(Dataset):\n",
        "    def __init__(self, hdf5_file, isic_ids, targets=None, transform=None, vsurf_features=None):\n",
        "        self.hdf5_file = h5py.File(hdf5_file, 'r')\n",
        "        self.isic_ids = isic_ids\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "        self.vsurf_features = vsurf_features\n",
        "        self.valid_indices = self._get_valid_indices()\n",
        "\n",
        "    def _get_valid_indices(self):\n",
        "        valid_indices = []\n",
        "        for idx in range(len(self.isic_ids)):\n",
        "            try:\n",
        "                img_bytes = self.hdf5_file[self.isic_ids[idx]][()]\n",
        "                Image.open(io.BytesIO(img_bytes))\n",
        "                valid_indices.append(idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing image at index {idx}: {e}\")\n",
        "        return valid_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx = self.valid_indices[idx]\n",
        "        img_bytes = self.hdf5_file[self.isic_ids[real_idx]][()]\n",
        "        img = Image.open(io.BytesIO(img_bytes))\n",
        "        img = np.array(img)\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)['image']\n",
        "        vsurf_feat = self.vsurf_features[real_idx] if self.vsurf_features is not None else np.zeros(5)\n",
        "        target = self.targets[real_idx] if self.targets is not None else None\n",
        "        return img, vsurf_feat, target\n",
        "\n",
        "    def __del__(self):\n",
        "        self.hdf5_file.close()\n",
        "\n",
        "def get_augmentation(is_training=True):\n",
        "    if is_training:\n",
        "        return A.Compose([\n",
        "            A.RandomResizedCrop(height=224, width=224, scale=(0.8, 1.0)),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
        "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
        "            A.CoarseDropout(max_holes=8, max_height=8, max_width=8, min_holes=5, min_height=8, min_width=8, fill_value=0, p=0.5),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(224, 224),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2(),\n",
        "        ])"
      ],
      "metadata": {
        "id": "jK27ucTb1HDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk 3: Train-Validation-Test Split, Random Oversampling, and DataLoader\n",
        "\n",
        "def perform_oversampling(df_train, vsurf_features=None):\n",
        "    X = df_train['isic_id'].values.reshape(-1, 1)\n",
        "    y = df_train['target'].values\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "\n",
        "    resampled_vsurf_features = vsurf_features[ros.sample_indices_] if vsurf_features is not None else None\n",
        "\n",
        "    resampled_df = pd.DataFrame({\n",
        "        'isic_id': X_resampled.flatten(),\n",
        "        'target': y_resampled\n",
        "    })\n",
        "\n",
        "    return resampled_df, resampled_vsurf_features\n",
        "\n",
        "# Split data into train (70%), validation (15%), and test (15%)\n",
        "train_df, temp_df = train_test_split(df_train, test_size=0.3, stratify=df_train['target'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['target'], random_state=42)\n",
        "\n",
        "print(f\"Train set: {len(train_df)} samples, Validation set: {len(val_df)} samples, Test set: {len(test_df)} samples\")\n",
        "\n",
        "def get_dataloaders(df, hdf5_file_path, batch_size, vsurf_features=None, is_training=True):\n",
        "    dataset = ISICDataset(hdf5_file_path,\n",
        "                          df['isic_id'].values,\n",
        "                          df['target'].values,\n",
        "                          transform=get_augmentation(is_training),\n",
        "                          vsurf_features=vsurf_features)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=is_training, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfi9uy0D1LE-",
        "outputId": "19b4cb85-2100-4de2-af14-e56dfeba2c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 280741 samples, Validation set: 60159 samples, Test set: 60159 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk 4: Model Setup, Checkpointing Functions, and Objective Function with VSURF features\n",
        "# JSON logging of hyperparameters for easier sharing of outputs\n",
        "\n",
        "class SqueezeNetWithVSURF(nn.Module):\n",
        "    def __init__(self, num_classes=1, vsurf_size=5, dropout_rate=0.5):\n",
        "        super(SqueezeNetWithVSURF, self).__init__()\n",
        "\n",
        "        # Load pre-trained SqueezeNet\n",
        "        self.squeezenet = models.squeezenet1_1(pretrained=True)\n",
        "\n",
        "        # Replace the last convolutional layer\n",
        "        self.squeezenet.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n",
        "\n",
        "        # Additional layers for VSURF features\n",
        "        self.vsurf_fc = nn.Sequential(\n",
        "            nn.Linear(vsurf_size, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "\n",
        "        # Combine features\n",
        "        self.final_fc = nn.Linear(num_classes + 32, num_classes)\n",
        "\n",
        "    def forward(self, x, vsurf):\n",
        "        # SqueezeNet forward pass\n",
        "        x = self.squeezenet(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # VSURF features forward pass\n",
        "        vsurf = self.vsurf_fc(vsurf)\n",
        "\n",
        "        # Combine features\n",
        "        combined = torch.cat((x, vsurf), dim=1)\n",
        "\n",
        "        # Final classification\n",
        "        out = self.final_fc(combined)\n",
        "\n",
        "        return out\n",
        "\n",
        "def setup_model(num_classes=1, vsurf_size=5, dropout_rate=0.5):\n",
        "    model = SqueezeNetWithVSURF(num_classes=num_classes, vsurf_size=vsurf_size, dropout_rate=dropout_rate)\n",
        "    return model.to(device)\n",
        "\n",
        "def save_checkpoint(epoch, model, optimizer, learning_rate, batch_size, dropout_rate):\n",
        "    os.makedirs('bes_checkpoints', exist_ok=True)\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'learning_rate': learning_rate,\n",
        "        'batch_size': batch_size,\n",
        "        'dropout_rate': dropout_rate\n",
        "    }\n",
        "    checkpoint_path = f\"bes_checkpoints/bes_checkpoint_epoch_{epoch}.pth\"\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    logging.info(f\"Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "def load_latest_checkpoint():\n",
        "    if not os.path.exists(\"bes_checkpoints\"):\n",
        "        logging.info(\"Checkpoint directory does not exist, starting from scratch.\")\n",
        "        return None\n",
        "\n",
        "    checkpoints = [f for f in os.listdir(\"bes_checkpoints\") if f.startswith(\"bes_checkpoint_epoch_\")]\n",
        "    if not checkpoints:\n",
        "        logging.info(\"No checkpoints found, starting from scratch.\")\n",
        "        return None\n",
        "\n",
        "    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "    checkpoint_path = os.path.join(\"bes_checkpoints\", latest_checkpoint)\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    model = setup_model(num_classes=1, dropout_rate=checkpoint['dropout_rate'])\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=checkpoint['learning_rate'], weight_decay=1e-5)\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    logging.info(f\"Loaded checkpoint: {checkpoint_path}\")\n",
        "    return checkpoint, model, optimizer\n",
        "\n",
        "def train_and_evaluate_model(model, optimizer, scheduler, train_loader, val_loader, num_epochs=10, patience=5):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    scaler = GradScaler()\n",
        "    best_val_f1 = 0\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for images, vsurf_features, targets in train_loader:\n",
        "            images = images.to(device)\n",
        "            vsurf_features = vsurf_features.to(device).float()  # Ensure float type\n",
        "            targets = targets.to(device).float().view(-1, 1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "                outputs = model(images, vsurf_features)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        val_f1 = evaluate_model(model, val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "        scheduler.step(val_f1)\n",
        "\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            epochs_without_improvement = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "                break\n",
        "\n",
        "    return best_val_f1\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    all_targets = []\n",
        "    all_outputs = []\n",
        "\n",
        "    for images, vsurf_features, targets in val_loader:\n",
        "        images = images.to(device)\n",
        "        vsurf_features = vsurf_features.to(device).float()  # Ensure float type\n",
        "        outputs = model(images, vsurf_features)\n",
        "\n",
        "        all_outputs.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "        all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "    binary_outputs = (np.array(all_outputs) > 0.5).astype(int)\n",
        "    val_f1 = f1_score(all_targets, binary_outputs)\n",
        "\n",
        "    return val_f1\n",
        "\n",
        "def log_hyperparameters(hyperparameters, metrics, model_name, dataset_info):\n",
        "    log = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"model\": model_name,\n",
        "        \"dataset\": dataset_info,\n",
        "        \"hyperparameters\": hyperparameters,\n",
        "        \"performance_metrics\": metrics\n",
        "    }\n",
        "\n",
        "    # Save as JSON for easy reading and sharing\n",
        "    with open('hyperparameters_log.json', 'w') as f:\n",
        "        json.dump(log, f, indent=4)\n",
        "\n",
        "    # Also save as .pth for PyTorch compatibility\n",
        "    torch.save(log, 'hyperparameters_log.pth')\n",
        "\n",
        "def objective_function(solution):\n",
        "    try:\n",
        "        learning_rate, dropout_rate = solution\n",
        "        batch_size = 64  # Fixed batch size, you can make this a parameter if needed\n",
        "\n",
        "        logging.info(f\"Trying solution: LR={learning_rate:.6f}, DR={dropout_rate:.2f}\")\n",
        "\n",
        "        train_df, val_df = train_test_split(df_train, test_size=0.2, stratify=df_train['target'], random_state=42)\n",
        "\n",
        "        vsurf_columns = ['clin_size_long_diam_mm', 'tbp_lv_H', 'tbp_lv_deltaLBnorm', 'tbp_lv_perimeterMM', 'tbp_lv_Hext']\n",
        "        vsurf_features = df_train[vsurf_columns].values\n",
        "\n",
        "        df_train_resampled, resampled_vsurf_features = perform_oversampling(train_df, vsurf_features=vsurf_features[train_df.index])\n",
        "\n",
        "        train_loader = get_dataloaders(df_train_resampled, local_hdf5_path, batch_size, vsurf_features=resampled_vsurf_features)\n",
        "        val_loader = get_dataloaders(val_df, local_hdf5_path, batch_size, vsurf_features=vsurf_features[val_df.index], is_training=False)\n",
        "\n",
        "        model = setup_model(num_classes=1, dropout_rate=dropout_rate, vsurf_size=5)\n",
        "        optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "        best_val_f1 = train_and_evaluate_model(model, optimizer, scheduler, train_loader, val_loader, num_epochs=3)\n",
        "\n",
        "        # Prepare data for logging\n",
        "        best_hyperparameters = {\n",
        "            'learning_rate': learning_rate,\n",
        "            'dropout_rate': dropout_rate\n",
        "        }\n",
        "\n",
        "        metrics = {\n",
        "            'val_f1': best_val_f1,\n",
        "        }\n",
        "\n",
        "        dataset_info = {\n",
        "            \"name\": \"ISIC 2024 Challenge\",\n",
        "            \"total_samples\": len(df_train),\n",
        "            \"benign_samples\": len(df_train[df_train['target'] == 0]),\n",
        "            \"malignant_samples\": len(df_train[df_train['target'] == 1])\n",
        "        }\n",
        "\n",
        "        # Log hyperparameters\n",
        "        log_hyperparameters(best_hyperparameters, metrics, \"SqueezeNet\", dataset_info)\n",
        "\n",
        "        # Save the current best solution\n",
        "        current_best = {\n",
        "            'learning_rate': learning_rate,\n",
        "            'dropout_rate': dropout_rate,\n",
        "            'val_f1': best_val_f1\n",
        "        }\n",
        "        torch.save(current_best, 'current_best_hyperparameters.pth')\n",
        "\n",
        "        logging.info(f\"Solution performance: F1={best_val_f1:.4f}\")\n",
        "\n",
        "        return -best_val_f1  # We're minimizing, so return negative F1 score\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in objective function: {str(e)}\")\n",
        "        return float('inf')  # Return large value to indicate failure\n"
      ],
      "metadata": {
        "id": "vb-2fejR1NFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk 5: BES Optimization Setup\n",
        "\n",
        "# Define the problem dictionary\n",
        "problem_dict = {\n",
        "    \"obj_func\": objective_function,\n",
        "    \"bounds\": FloatVar(\n",
        "        lb=[1e-5, 0.1],  # Lower bounds: learning_rate, dropout_rate\n",
        "        ub=[1e-3, 0.5],  # Upper bounds: learning_rate, dropout_rate\n",
        "        name=[\"learning_rate\", \"dropout_rate\"]\n",
        "    ),\n",
        "    \"minmax\": \"min\",  # We want to minimize the objective function (negative F1 score)\n",
        "}\n",
        "\n",
        "# BES Optimizer Setup\n",
        "optimizer = BES.OriginalBES(\n",
        "    epoch=50,\n",
        "    pop_size=10,\n",
        "    a_factor=10,\n",
        "    R_factor=1.5,\n",
        "    alpha=2.0,\n",
        "    c1=2.0,\n",
        "    c2=2.0\n",
        ")\n",
        "\n",
        "# Set a callback function to save checkpoints after each epoch\n",
        "def checkpoint_callback(epoch, population):\n",
        "    os.makedirs('bes_checkpoints', exist_ok=True)\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'population': population\n",
        "    }\n",
        "    checkpoint_path = f\"bes_checkpoints/bes_checkpoint_epoch_{epoch}.pth\"\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    logging.info(f\"Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "optimizer.callback = checkpoint_callback\n",
        "\n",
        "# Define termination conditions\n",
        "term_dict = {\n",
        "    \"max_epoch\": 50,\n",
        "    \"max_fe\": 1000,\n",
        "    \"max_time\": 14400,  # 4 hours in seconds\n",
        "    \"max_early_stop\": 30\n",
        "}\n",
        "\n",
        "# Check for an existing checkpoint to resume optimization\n",
        "latest_checkpoint = load_latest_checkpoint()\n",
        "if latest_checkpoint:\n",
        "    start_epoch = latest_checkpoint['epoch']\n",
        "    optimizer.g_best = latest_checkpoint['g_best']\n",
        "    optimizer.pop = latest_checkpoint['pop']\n",
        "    optimizer.epoch = start_epoch\n",
        "    logging.info(f\"Resuming optimization from epoch {start_epoch}\")\n",
        "else:\n",
        "    start_epoch = 0\n",
        "    logging.info(\"Starting new optimization process\")\n",
        "\n",
        "# Solve the optimization problem using BES\n",
        "try:\n",
        "    best_solution, best_fitness = optimizer.solve(problem_dict, termination=term_dict)\n",
        "\n",
        "    logging.info(\"Optimization completed successfully.\")\n",
        "    logging.info(f\"Best Hyperparameters: Learning Rate = {best_solution[0]:.6f}, \"\n",
        "                 f\"Dropout Rate = {best_solution[1]:.2f}\")\n",
        "    logging.info(f\"Best Validation F1 Score: {-best_fitness:.4f}\")\n",
        "\n",
        "    # Output the results\n",
        "    print(\"Optimization completed.\")\n",
        "    print(f\"Best Hyperparameters: Learning Rate = {best_solution[0]:.6f}, \"\n",
        "          f\"Dropout Rate = {best_solution[1]:.2f}\")\n",
        "    print(f\"Best Validation F1 Score: {-best_fitness:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during optimization process: {str(e)}\")\n",
        "    print(f\"An error occurred during optimization. Check the log file for details.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vc8pTJFy1cJq",
        "outputId": "70437383-2971-474c-a400-63d46014b5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_1-b8a52dc0.pth\n",
            "100%|██████████| 4.73M/4.73M [00:00<00:00, 103MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.5397, Val F1: 0.0106\n",
            "Epoch 2/3, Train Loss: 0.4367, Val F1: 0.0117\n",
            "Epoch 3/3, Train Loss: 0.4160, Val F1: 0.0124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:mealpy.swarm_based.BES.OriginalBES:Solving single objective optimization problem.\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.8841, Val F1: 0.0088\n",
            "Epoch 2/3, Train Loss: 0.4316, Val F1: 0.0150\n",
            "Epoch 3/3, Train Loss: 0.3563, Val F1: 0.0144\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.3103, Val F1: 0.0368\n",
            "Epoch 2/3, Train Loss: 0.1058, Val F1: 0.0537\n",
            "Epoch 3/3, Train Loss: 0.0669, Val F1: 0.0490\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.2757, Val F1: 0.0487\n",
            "Epoch 2/3, Train Loss: 0.0531, Val F1: 0.0413\n",
            "Epoch 3/3, Train Loss: 0.0323, Val F1: 0.0580\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.6286, Val F1: 0.0089\n",
            "Epoch 2/3, Train Loss: 0.5175, Val F1: 0.0092\n",
            "Epoch 3/3, Train Loss: 0.4948, Val F1: 0.0101\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.5317, Val F1: 0.0118\n",
            "Epoch 2/3, Train Loss: 0.3625, Val F1: 0.0160\n",
            "Epoch 3/3, Train Loss: 0.3274, Val F1: 0.0276\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.2280, Val F1: 0.0482\n",
            "Epoch 2/3, Train Loss: 0.0557, Val F1: 0.0604\n",
            "Epoch 3/3, Train Loss: 0.0317, Val F1: 0.0733\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: nan, Val F1: 0.0000\n",
            "Epoch 2/3, Train Loss: nan, Val F1: 0.0000\n",
            "Epoch 3/3, Train Loss: nan, Val F1: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.5161, Val F1: 0.0122\n",
            "Epoch 2/3, Train Loss: 0.4040, Val F1: 0.0130\n",
            "Epoch 3/3, Train Loss: 0.3783, Val F1: 0.0137\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.4966, Val F1: 0.0107\n",
            "Epoch 2/3, Train Loss: 0.4192, Val F1: 0.0132\n",
            "Epoch 3/3, Train Loss: 0.4083, Val F1: 0.0108\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.2659, Val F1: 0.0331\n",
            "Epoch 2/3, Train Loss: 0.0779, Val F1: 0.0467\n",
            "Epoch 3/3, Train Loss: 0.0470, Val F1: 0.0530\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.2202, Val F1: 0.0441\n",
            "Epoch 2/3, Train Loss: 0.0428, Val F1: 0.0616\n",
            "Epoch 3/3, Train Loss: 0.0265, Val F1: 0.0677\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Train Loss: 0.8548, Val F1: 0.0151\n",
            "Epoch 2/3, Train Loss: 0.3897, Val F1: 0.0290\n",
            "Epoch 3/3, Train Loss: 0.2347, Val F1: 0.0323\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 0.2062, Val F1: 0.0597\n",
            "Epoch 2/3, Train Loss: 0.0468, Val F1: 0.0398\n",
            "Epoch 3/3, Train Loss: 0.0284, Val F1: 0.0738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 0.6834, Val F1: 0.0092\n",
            "Epoch 2/3, Train Loss: 0.4858, Val F1: 0.0113\n",
            "Epoch 3/3, Train Loss: 0.4479, Val F1: 0.0111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 0.1907, Val F1: 0.0586\n",
            "Epoch 2/3, Train Loss: 0.0452, Val F1: 0.0654\n",
            "Epoch 3/3, Train Loss: 0.0288, Val F1: 0.0599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 0.2953, Val F1: 0.0291\n",
            "Epoch 2/3, Train Loss: 0.0930, Val F1: 0.0418\n",
            "Epoch 3/3, Train Loss: 0.0558, Val F1: 0.0442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 1.4245, Val F1: 0.0144\n",
            "Epoch 2/3, Train Loss: 0.4310, Val F1: 0.0139\n",
            "Epoch 3/3, Train Loss: 0.3170, Val F1: 0.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 0.2472, Val F1: 0.0525\n",
            "Epoch 2/3, Train Loss: 0.0566, Val F1: 0.0447\n",
            "Epoch 3/3, Train Loss: 0.0350, Val F1: 0.0360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 2.3329, Val F1: 0.0158\n",
            "Epoch 2/3, Train Loss: 0.3973, Val F1: 0.0218\n",
            "Epoch 3/3, Train Loss: 0.2530, Val F1: 0.0311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 0.5138, Val F1: 0.0222\n",
            "Epoch 2/3, Train Loss: 0.1506, Val F1: 0.0329\n",
            "Epoch 3/3, Train Loss: 0.0842, Val F1: 0.0446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 0.2408, Val F1: 0.0252\n",
            "Epoch 2/3, Train Loss: 0.0576, Val F1: 0.0359\n",
            "Epoch 3/3, Train Loss: 0.0361, Val F1: 0.0661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: nan, Val F1: 0.0000\n",
            "Epoch 2/3, Train Loss: nan, Val F1: 0.0000\n",
            "Epoch 3/3, Train Loss: nan, Val F1: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 0.3944, Val F1: 0.0267\n",
            "Epoch 2/3, Train Loss: 0.0807, Val F1: 0.0822\n",
            "Epoch 3/3, Train Loss: 0.0442, Val F1: 0.0657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8f9df76c0d4b>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Solve the optimization problem using BES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mbest_solution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mterm_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimization completed successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mealpy/optimizer.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, problem, mode, n_workers, termination, starting_solutions, seed)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m## Evolve method will be called in child class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;31m# Update global best solution, the population is sorted or not depended on algorithm's strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mealpy/swarm_based/BES.py\u001b[0m in \u001b[0;36mevolve\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mpop_child\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAVAILABLE_MODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_better_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAVAILABLE_MODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mealpy/optimizer.py\u001b[0m in \u001b[0;36mget_target\u001b[0;34m(self, solution, counted)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcounted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mealpy/utils/problem.py\u001b[0m in \u001b[0;36mget_target\u001b[0;34m(self, solution)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjectives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-85df465c5c29>\u001b[0m in \u001b[0;36mobjective_function\u001b[0;34m(solution)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mbest_val_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Prepare data for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-85df465c5c29>\u001b[0m in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model, optimizer, scheduler, train_loader, val_loader, num_epochs, patience)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvsurf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mvsurf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvsurf_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure float type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk 6: Model evaluation with Kaggle pAUC scoring\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score, classification_report\n",
        "\n",
        "def competition_score(y_true, y_pred, min_tpr=0.80):\n",
        "    # Rescale the target. Set 0s to 1s and 1s to 0s\n",
        "    v_gt = abs(np.asarray(y_true) - 1)\n",
        "    # Flip the predictions to their complements\n",
        "    v_pred = -1.0 * np.asarray(y_pred)\n",
        "    max_fpr = abs(1 - min_tpr)\n",
        "    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n",
        "    if max_fpr is None or max_fpr == 1:\n",
        "        return auc(fpr, tpr)\n",
        "    if max_fpr <= 0 or max_fpr > 1:\n",
        "        raise ValueError(f\"Expected min_tpr in range [0, 1), got: {min_tpr}\")\n",
        "    # Add a single point at max_fpr by linear interpolation\n",
        "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
        "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
        "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
        "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
        "    fpr = np.append(fpr[:stop], max_fpr)\n",
        "    partial_auc = auc(fpr, tpr)\n",
        "    return partial_auc, fpr, tpr\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    for inputs, vsurf_features, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        inputs = inputs.to(device)\n",
        "        vsurf_features = vsurf_features.to(device).float()\n",
        "        outputs = model(inputs, vsurf_features)\n",
        "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
        "        all_predictions.append(predictions)\n",
        "        all_targets.append(targets.numpy())\n",
        "\n",
        "    all_predictions = np.concatenate(all_predictions).flatten()\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "\n",
        "    # Print diagnostic information\n",
        "    print(f\"Predictions - Min: {all_predictions.min():.4f}, Max: {all_predictions.max():.4f}, Mean: {all_predictions.mean():.4f}\")\n",
        "    print(f\"Unique prediction values: {len(np.unique(all_predictions))}\")\n",
        "    print(f\"Prediction distribution:\\n{np.histogram(all_predictions, bins=10)}\")\n",
        "    print(f\"Target distribution: {np.bincount(all_targets)}\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    try:\n",
        "        auc_score = roc_auc_score(all_targets, all_predictions)\n",
        "        pauc_score, fpr, tpr = competition_score(all_targets, all_predictions, min_tpr=0.80)\n",
        "        print(f\"ROC curve points: {len(fpr)}\")\n",
        "        print(f\"TPR range: {tpr.min():.4f} to {tpr.max():.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: AUC calculation failed. Error: {str(e)}\")\n",
        "        print(\"Setting AUC and pAUC to minimum values.\")\n",
        "        auc_score = 0.5\n",
        "        pauc_score = 0.0\n",
        "        fpr, tpr = None, None\n",
        "\n",
        "    binary_predictions = (all_predictions > 0.5).astype(int)\n",
        "    f1 = f1_score(all_targets, binary_predictions)\n",
        "\n",
        "    print(f\"AUC: {auc_score:.4f}\")\n",
        "    print(f\"pAUC (competition metric): {pauc_score:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_targets, binary_predictions))\n",
        "\n",
        "    return auc_score, pauc_score, f1\n",
        "\n",
        "# Test the evaluate_model function\n",
        "print(\"Testing evaluate_model function:\")\n",
        "# Load the best model (assuming it's already trained and saved)\n",
        "best_model = setup_model(num_classes=1, vsurf_size=5, dropout_rate=best_hyperparameters['dropout_rate'])\n",
        "best_model.load_state_dict(torch.load('best_model.pth'))\n",
        "best_model = best_model.to(device)\n",
        "\n",
        "# Prepare the test dataset\n",
        "test_vsurf_features = test_df[vsurf_columns].values\n",
        "\n",
        "print(\"Test VSURF features shape:\", test_vsurf_features.shape)\n",
        "print(\"Test VSURF features type:\", type(test_vsurf_features))\n",
        "print(\"Test VSURF features dtype:\", test_vsurf_features.dtype)\n",
        "\n",
        "# Create a test loader for the test set\n",
        "test_loader = get_dataloaders(test_df, local_hdf5_path, batch_size=64, vsurf_features=test_vsurf_features, is_training=False)\n",
        "\n",
        "# Run the evaluation\n",
        "test_auc_score, test_pauc_score, test_f1_score = evaluate_model(best_model, test_loader, device)\n",
        "print(f\"Test AUC: {test_auc_score:.4f}\")\n",
        "print(f\"Test pAUC (competition metric): {test_pauc_score:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655,
          "referenced_widgets": [
            "0541d1e811a54e3c954e00d7b616bac5",
            "94f6477611074ef6a9f5ac4323e32e13",
            "1c33e049014b45dc93b735a21aaa2a49",
            "53f89ccc3d914780ab219946a5e201fe",
            "1d8dda237ab648bfb16f7ff73dacaafa",
            "f95495ada42745b6bec750cf97ad7ff6",
            "99017cc8d7fd4275b1e4588346454e2d",
            "84a24687be6a47bbba718c5087abfe85",
            "d41144987c0a45e0a1e7977ec873273e",
            "08af248b706543849e211180d4a31a40",
            "f7531edd3bb2456d85d674577c14877c"
          ]
        },
        "id": "X8LXjKEtbSb8",
        "outputId": "b0de4392-5633-47e1-a27c-ae172a734161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing evaluate_model function:\n",
            "Test VSURF features shape: (60159, 5)\n",
            "Test VSURF features type: <class 'numpy.ndarray'>\n",
            "Test VSURF features dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2681bc53a174>:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_model.load_state_dict(torch.load('best_model.pth'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/940 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0541d1e811a54e3c954e00d7b616bac5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions - Min: 0.0000, Max: 1.0000, Mean: 0.0076\n",
            "Unique prediction values: 59757\n",
            "Prediction distribution:\n",
            "(array([59347,   278,   119,    74,    52,    44,    50,    46,    46,\n",
            "         103]), array([9.44209751e-06, 1.00008436e-01, 2.00007439e-01, 3.00006419e-01,\n",
            "       4.00005430e-01, 5.00004411e-01, 6.00003421e-01, 7.00002432e-01,\n",
            "       8.00001383e-01, 9.00000393e-01, 9.99999404e-01], dtype=float32))\n",
            "Target distribution: [60100    59]\n",
            "ROC curve points: 814\n",
            "TPR range: 0.0000 to 0.8947\n",
            "AUC: 0.9272\n",
            "pAUC (competition metric): 0.1383\n",
            "F1 Score: 0.1552\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     60100\n",
            "           1       0.09      0.46      0.16        59\n",
            "\n",
            "    accuracy                           1.00     60159\n",
            "   macro avg       0.55      0.73      0.58     60159\n",
            "weighted avg       1.00      1.00      1.00     60159\n",
            "\n",
            "Test AUC: 0.9272\n",
            "Test pAUC (competition metric): 0.1383\n",
            "Test F1 Score: 0.1552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk 7: Test against validation set\n",
        "import traceback\n",
        "import torch\n",
        "\n",
        "# Load the best hyperparameters\n",
        "best_hyperparameters = torch.load('/content/current_best_hyperparameters.pth')\n",
        "print(\"Loaded best hyperparameters:\", best_hyperparameters)\n",
        "\n",
        "# Prepare the validation dataset\n",
        "vsurf_columns = ['clin_size_long_diam_mm', 'tbp_lv_H', 'tbp_lv_deltaLBnorm', 'tbp_lv_perimeterMM', 'tbp_lv_Hext']\n",
        "val_vsurf_features = val_df[vsurf_columns].values\n",
        "\n",
        "print(\"Validation VSURF features shape:\", val_vsurf_features.shape)\n",
        "print(\"Validation VSURF features type:\", type(val_vsurf_features))\n",
        "print(\"Validation VSURF features dtype:\", val_vsurf_features.dtype)\n",
        "\n",
        "# Create a DataLoader for the validation set\n",
        "val_loader = get_dataloaders(val_df, local_hdf5_path, batch_size=64, vsurf_features=val_vsurf_features, is_training=False)\n",
        "\n",
        "# Load the best model\n",
        "best_model = setup_model(num_classes=1, vsurf_size=5, dropout_rate=best_hyperparameters['dropout_rate'])\n",
        "best_model.load_state_dict(torch.load('best_model.pth'))\n",
        "best_model = best_model.to(device)\n",
        "\n",
        "# Make sure your model is in evaluation mode\n",
        "best_model.eval()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "print(\"Evaluating on Validation Set:\")\n",
        "try:\n",
        "    for batch_idx, (inputs, vsurf_features, targets) in enumerate(val_loader):\n",
        "        print(f\"\\nBatch {batch_idx}:\")\n",
        "        print(\"Inputs shape:\", inputs.shape)\n",
        "        print(\"VSURF features shape:\", vsurf_features.shape)\n",
        "        print(\"Targets shape:\", targets.shape)\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        vsurf_features = vsurf_features.to(device).float()\n",
        "\n",
        "        try:\n",
        "            outputs = best_model(inputs, vsurf_features)\n",
        "            print(\"Outputs shape:\", outputs.shape)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in model forward pass: {str(e)}\")\n",
        "            print(f\"Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "        if batch_idx == 0:  # Only print for the first batch\n",
        "            break\n",
        "\n",
        "    val_auc_score, val_pauc_score, val_f1_score = evaluate_model(best_model, val_loader, device)\n",
        "    print(f\"Validation AUC: {val_auc_score:.4f}\")\n",
        "    print(f\"Validation pAUC (competition metric): {val_pauc_score:.4f}\")\n",
        "    print(f\"Validation F1 Score: {val_f1_score:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during validation evaluation: {str(e)}\")\n",
        "    print(f\"Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "# Print model structure\n",
        "print(\"\\nModel structure:\")\n",
        "print(best_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d6a0d79bd6b84a4ca22381e05bf56bdf",
            "89a8a6211f804ec78c5b5fbde0186103",
            "125feb460af94b5faf993913d2aea489",
            "f1fae12dae104079be11126b6ef0d629",
            "458e67f01ae64a2a9804f9a98e56b094",
            "c638d43fdb7c438b8b2026b651be42f5",
            "7e443757050e4c9190920ccf2b84eb66",
            "9b90c93dc1e246f997fb383b8f9f1968",
            "df24fc1d08e74c549f548b2b6518b6ad",
            "af941bf8e0e944e8b58010c22afda7ee",
            "02c17eed95274a44bde100e7a63455d9"
          ]
        },
        "id": "kxeTmtsqUMaY",
        "outputId": "498ee126-011a-45e2-f20d-3f8033dfdf6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ec0b038caff6>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_hyperparameters = torch.load('/content/current_best_hyperparameters.pth')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded best hyperparameters: {'learning_rate': 0.00014742482211184204, 'dropout_rate': 0.1, 'val_f1': 0.0821917808219178}\n",
            "Validation VSURF features shape: (60159, 5)\n",
            "Validation VSURF features type: <class 'numpy.ndarray'>\n",
            "Validation VSURF features dtype: float64\n",
            "Evaluating on Validation Set:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-15-ec0b038caff6>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_model.load_state_dict(torch.load('best_model.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 0:\n",
            "Inputs shape: torch.Size([64, 3, 224, 224])\n",
            "VSURF features shape: torch.Size([64, 5])\n",
            "Targets shape: torch.Size([64])\n",
            "Outputs shape: torch.Size([64, 1])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/940 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6a0d79bd6b84a4ca22381e05bf56bdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions - Min: 0.0000, Max: 0.9999, Mean: 0.0069\n",
            "Unique prediction values: 59759\n",
            "Prediction distribution:\n",
            "(array([59417,   245,   111,    81,    48,    42,    42,    44,    41,\n",
            "          88]), array([1.2159118e-05, 1.0000154e-01, 1.9999091e-01, 2.9998028e-01,\n",
            "       3.9996967e-01, 4.9995905e-01, 5.9994841e-01, 6.9993782e-01,\n",
            "       7.9992718e-01, 8.9991659e-01, 9.9990594e-01], dtype=float32))\n",
            "Target distribution: [60100    59]\n",
            "ROC curve points: 808\n",
            "TPR range: 0.0000 to 0.9341\n",
            "AUC: 0.9469\n",
            "pAUC (competition metric): 0.1544\n",
            "F1 Score: 0.1899\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     60100\n",
            "           1       0.12      0.51      0.19        59\n",
            "\n",
            "    accuracy                           1.00     60159\n",
            "   macro avg       0.56      0.75      0.59     60159\n",
            "weighted avg       1.00      1.00      1.00     60159\n",
            "\n",
            "Validation AUC: 0.9469\n",
            "Validation pAUC (competition metric): 0.1544\n",
            "Validation F1 Score: 0.1899\n",
            "\n",
            "Model structure:\n",
            "SqueezeNetWithVSURF(\n",
            "  (squeezenet): SqueezeNet(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "      (3): Fire(\n",
            "        (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (squeeze_activation): ReLU(inplace=True)\n",
            "        (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (expand1x1_activation): ReLU(inplace=True)\n",
            "        (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (expand3x3_activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Fire(\n",
            "        (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (squeeze_activation): ReLU(inplace=True)\n",
            "        (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (expand1x1_activation): ReLU(inplace=True)\n",
            "        (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (expand3x3_activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "      (6): Fire(\n",
            "        (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (squeeze_activation): ReLU(inplace=True)\n",
            "        (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (expand1x1_activation): ReLU(inplace=True)\n",
            "        (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (expand3x3_activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (7): Fire(\n",
            "        (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (squeeze_activation): ReLU(inplace=True)\n",
            "        (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (expand1x1_activation): ReLU(inplace=True)\n",
            "        (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (expand3x3_activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "      (9): Fire(\n",
            "        (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (squeeze_activation): ReLU(inplace=True)\n",
            "        (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (expand1x1_activation): ReLU(inplace=True)\n",
            "        (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (expand3x3_activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (10): Fire(\n",
            "        (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (squeeze_activation): ReLU(inplace=True)\n",
            "        (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (expand1x1_activation): ReLU(inplace=True)\n",
            "        (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (expand3x3_activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Fire(\n",
            "        (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (squeeze_activation): ReLU(inplace=True)\n",
            "        (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (expand1x1_activation): ReLU(inplace=True)\n",
            "        (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (expand3x3_activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (12): Fire(\n",
            "        (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (squeeze_activation): ReLU(inplace=True)\n",
            "        (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (expand1x1_activation): ReLU(inplace=True)\n",
            "        (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (expand3x3_activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (classifier): Sequential(\n",
            "      (0): Dropout(p=0.5, inplace=False)\n",
            "      (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (vsurf_fc): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (final_fc): Linear(in_features=33, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}